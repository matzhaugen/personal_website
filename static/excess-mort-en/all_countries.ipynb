{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea9de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(stringr)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(lubridate)\n",
    "library(ISOweek)\n",
    "library(scales)\n",
    "library(zoo)\n",
    "library(tidyr)\n",
    "library(quantreg)\n",
    "library(splines)\n",
    "library(pbs)\n",
    "library(forecast)\n",
    "require(RcppRoll)\n",
    "library(fpp2)\n",
    "library(xts)\n",
    "theme_set(theme_bw())\n",
    "get_percentage = function(x) {\n",
    "    (exp(x) - 1) * 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5613a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also redownload the data with the get_data.r script\n",
    "# The data seems to be\n",
    "df = read.csv(\"../data/stmf.csv\", skip=1)\n",
    "n_rows = nrow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Weekday\"] = \"1\"\n",
    "df$Week = str_pad(df$Week, 2, pad=\"0\")\n",
    "data = df %>% unite(Weekdate, \"Year\", \"Week\", sep=\"-W\", remove=FALSE)\n",
    "data = data %>% unite(Weekdate, \"Weekdate\", \"Weekday\", sep=\"-\")\n",
    "data$Date = ISOweek2date(data$Weekdate)\n",
    "death_cols = c(\"D0_14\", \"D15_64\", \"D65_74\", \"D75_84\", \"D85p\")\n",
    "rate_cols = c(\"R0_14\", \"R15_64\", \"R65_74\", \"R75_84\", \"R85p\")\n",
    "base_cols = c(\"CountryCode\", \"Weekdate\", \"Year\", \"Week\", \"Sex\")\n",
    "data = data %>% pivot_longer(all_of(c(death_cols, rate_cols)), names_pattern=\"(.)(.*)\", names_to=c(\"Type\", \"Age\")) %>% pivot_wider(names_from=Type, values_from=value)# data$Pop = data$Deaths / data$Rates\n",
    "data = rename(data, Deaths = D)\n",
    "data = rename(data, Rates = R)\n",
    "data$Pop = data$Deaths / data$Rates\n",
    "\n",
    "data = data %>% group_by(Age, Sex, CountryCode) %>% fill(Pop, .direction=\"up\")\n",
    "data$Pop_int = data$Pop\n",
    "data$Pop_int[data$Week != 52] = NA\n",
    "data = data[data$Week != 53, ]\n",
    "data = data %>%\n",
    "    group_by(Sex, Age, CountryCode) %>%\n",
    "    arrange(Date) %>%\n",
    "    mutate(time=seq(1, n())) %>% \n",
    "    mutate(Pop_int=approx(time,Pop_int,time)$y) %>%\n",
    "    fill(Pop_int, .direction=\"downup\") %>%\n",
    "    select(-time)\n",
    "data$Rate_norm = data$Deaths / data$Pop_int\n",
    "\n",
    "# European Standard population numbers\n",
    "# Get the ESP groups\n",
    "std_esp_pop = c(1000, 4000, 5500, 5500, 5500, 6000, 6000, 6500, 7000, \n",
    "            7000, 7000, 7000, 6500, 6000, 5500, 5000, 4000, 2500, 1500, 800, 200)\n",
    "esp_group = cut(c(0:100), c(0,1,seq(5,95, 5), 200), right=FALSE)\n",
    "age = c(\"0_14\", \"15_64\", \"65_74\", \"75_84\", \"85p\")\n",
    "esp_pop = c(sum(std_esp_pop[1:4]), sum(std_esp_pop[5:14]), sum(std_esp_pop[15:16]), sum(std_esp_pop[17:18]), sum(std_esp_pop[19:21]))\n",
    "esp_df = data.frame(Age=age, Esp_pop=esp_pop)\n",
    "esp_groups = levels(esp_group)\n",
    "std_esp_df = data.frame(age=esp_groups, esp_pop=std_esp_pop)\n",
    "data = merge(data, esp_df, by=\"Age\")\n",
    "data$Deaths_norm = data$Rate_norm * data$Esp_pop\n",
    "sprintf(\"Fraction of data missing %.2f\", dim(data[data$Deaths_norm==0,])[1] / dim(data)[1])\n",
    "# With a smoother we are down to 3%. This is managable\n",
    "# Define functions\n",
    "weighted_mean = function(x) {\n",
    "    nas = is.na(x)\n",
    "    w = c(0.25, 0.5, 0.25)\n",
    "    if (all(nas)) {\n",
    "        return(0)\n",
    "    } else {\n",
    "        w = w[!nas] / sum(w[!nas])\n",
    "        return(sum(x[!nas] * w))\n",
    "    }\n",
    "}\n",
    "sprintf(\"Smoothing...\")\n",
    "data <- data %>% group_by(Age, CountryCode, Sex) %>% arrange(Sex, Age, Date) %>%\n",
    "       mutate(Sdeaths_norm=rollapply(Deaths_norm, 3, weighted_mean, align='center', fill=NA))\n",
    "sprintf(\"Fraction of data missing after smoothing %.2f\", dim(data[data$Sdeaths_norm==0,])[1] / dim(data)[1])\n",
    "\n",
    "data = data %>% fill(Sdeaths_norm, .direction=\"downup\") %>% filter(Sdeaths_norm > 0)\n",
    "\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mortality_fit = function(\n",
    "    data, \n",
    "    # Parameters\n",
    "    years_per_df = 5,\n",
    "    df.weekly = 4,\n",
    "    df.res = 2,\n",
    "    alpha=0.10,\n",
    "    response.col = \"Sdeaths_norm\",\n",
    "    debug=FALSE,\n",
    "    cv=FALSE) {\n",
    "    # This function fits trends and confidence intervals at the alpha level\n",
    "    # Enforced column names in input data\n",
    "    \n",
    "    test_start_year = 2020\n",
    "    start_year = 2012\n",
    "    \n",
    "    week.col = \"Week\"\n",
    "    year.col = \"Year\"\n",
    "    date.col = \"Date\"\n",
    "    sex.col = \"Sex\"\n",
    "    country.col = \"CountryCode\"\n",
    "    age.col = \"Age\"\n",
    "\n",
    "    all = data.frame(date = data[,date.col],\n",
    "                    week = as.numeric(unlist(data[,week.col])),\n",
    "                    year = as.numeric(unlist(data[,year.col])),\n",
    "                    response=log(data[, response.col]),\n",
    "                    sex = as.factor(unlist(data[,sex.col])),\n",
    "                    country = as.factor(unlist(data[,country.col])),\n",
    "                    age = as.factor(unlist(data[,age.col])))\n",
    "    \n",
    "    colnames(all) = c(\"date\", \"week\", \"year\", \"response\", \"sex\", \"country\", \"age\")\n",
    "    df.yearly = floor(max((test_start_year - min(all$year)) / years_per_df, 2))\n",
    "    print(sprintf(\"Using %d degrees of freedom in yearly splines for %s, %s, %s\", \n",
    "            df.yearly, all$country[1], all$age[1], all$sex[1]))\n",
    "    all = subset(all, year(date) > start_year)\n",
    "    train = subset(all, year(date) < test_start_year)\n",
    "    test = subset(all, year(date) >= test_start_year)\n",
    "\n",
    "    yearly.fit = rq(response ~ ns(date, df=df.yearly), data=train)\n",
    "\n",
    "    train[, \"res.yearly\"] = yearly.fit$res\n",
    "    train[, \"fit.yearly\"] = yearly.fit$fit\n",
    "    weekly.fit = rq(res.yearly ~ 0 + pbs(week, df=df.weekly), data=train)\n",
    "    \n",
    "    train[, \"fit.weekly\"] = weekly.fit$fit\n",
    "    train[, \"res.weekly\"] = weekly.fit$res\n",
    "    train = train %>% mutate(centered = response - fit.weekly - fit.yearly)\n",
    "    # Set test date to last train date to fix yearly trend in test period\n",
    "    mod_date = all$date\n",
    "    mod_date[year(mod_date) >= test_start_year] = as.Date(\"2019-12-31\", \"%Y-%m-%d\")\n",
    "    mod_all = data.frame(date=mod_date, week=all$week)\n",
    "    all$fit.yearly = predict(yearly.fit, newdata=mod_all)\n",
    "    all$fit.weekly = predict(weekly.fit, newdata=mod_all)\n",
    "    \n",
    "    all = all %>% mutate(centered = response - fit.weekly - fit.yearly)\n",
    "    n_train = nrow(train)\n",
    "    n_all = nrow(all)\n",
    "    # Simple constant quantile c.i.\n",
    "    if (df.res <= 2) {\n",
    "        fit.low = quantile(train$centered, alpha/2)\n",
    "        fit.high = quantile(train$centered, 1 - alpha/2)\n",
    "        train$centered_high = rep(fit.high, n_train)\n",
    "        train$centered_low = rep(fit.low, n_train)\n",
    "        all$centered_high = rep(fit.high, n_all)\n",
    "        all$centered_low = rep(fit.low, n_all)\n",
    "    } else {\n",
    "        fit.low = rq(centered ~ 0 + pbs(week, df=df.res), data=train, tau=alpha/2)\n",
    "        fit.high = rq(centered ~ 0 + pbs(week, df=df.res), data=train, tau=1-alpha/2)\n",
    "        train$centered_high = fit.high$fit\n",
    "        train$centered_low = fit.low$fit\n",
    "        all$centered_high = predict(fit.high, newdata=all)\n",
    "        all$centered_low = predict(fit.low, newdata=all)\n",
    "    }\n",
    "    \n",
    "    test = subset(all, year(date) > 2020)\n",
    "    frac_outside = sum(train$centered < train$centered_low | train$centered > train$centered_high) / nrow(train)\n",
    "    frac_outside_test = sum(test$centered < test$centered_low | test$centered > test$centered_high) / nrow(test)\n",
    "    frac_over_test = sum(test$centered > test$centered_high) / nrow(test)\n",
    "    if (debug) {\n",
    "        print(sprintf(\"Fraction of observations outside confidence band in pre-2020: %.3f\", frac_outside))\n",
    "        print(sprintf(\"Fraction of observations outside confidence band in 2021: %.3f\", frac_outside_test))\n",
    "        print(sprintf(\"Fraction of observations over confidence band in 2021: %.3f\", frac_over_test))\n",
    "    }\n",
    "    if (cv) {\n",
    "        return(list(df=all, weekly.fit=weekly.fit))\n",
    "    }\n",
    "    return(all)\n",
    "}\n",
    "\n",
    "plot_debug = function(df) {\n",
    "    ggplot(df, aes(date, response)) + geom_line(alpha=0.3) + \n",
    "    geom_line(aes(date, fit.yearly), size=1.5, color=\"blue\") + \n",
    "    geom_line(aes(date, fit.weekly + fit.yearly), size=1.5, color=\"gold\") +\n",
    "    geom_ribbon(aes(ymin=centered_low + fit.weekly + fit.yearly, \n",
    "                    ymax=centered_high + fit.weekly + fit.yearly), alpha=0.3) + \n",
    "    labs(x=\"Date\", y=\"Deaths [per 100k per week]\", title=\"Anomalous Mortality 2012-2022\") \n",
    "}\n",
    "plot_mortality = function(df) {\n",
    "    ggplot(df, aes(date, get_percentage(centered))) + geom_line(alpha=0.3) + \n",
    "    geom_smooth(method=\"lm\", formula=y ~ ns(x, df=16), se=FALSE) +\n",
    "    geom_ribbon(aes(ymin=get_percentage(centered_low), ymax=get_percentage(centered_high)), alpha=0.3) + \n",
    "    labs(x=\"Date\", y=\"Deaths [% from baseline 2014-2019]\", title=\"Anomalous Mortality 2012-2022\") \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762219a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified = data %>% group_by(CountryCode, Sex, Age) %>% group_map(~ mortality_fit(.x, response.col=\"Sdeaths_norm\"), keep=TRUE)\n",
    "stratified = do.call(rbind, stratified)\n",
    "# stratified_dfres = data %>% group_by(CountryCode, Sex, Age) %>% group_map(~ mortality_fit(.x, response.col=\"Sdeaths_norm\", df.res=6), keep=TRUE)\n",
    "# stratified_dfres = do.call(rbind, stratified_dfres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset\n",
    "options(repr.plot.width=9, repr.plot.height=4)\n",
    "plot_mortality(subset(stratified, country==\"USA\" & age==\"15_64\" & sex==\"b\" & year >= 2016))\n",
    "# plot_mortality(subset(stratified_dfres, country==\"USA\" & age==\"15_64\" & sex==\"b\" & year >= 2016))\n",
    "# plot_mortality(subset(stratified, country==country & age==\"65_74\" & sex==\"b\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a4797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset\n",
    "options(repr.plot.width=9, repr.plot.height=4)\n",
    "# cdata = subset(stratified, country==\"NOR\" & age==\"65_74\" & sex==\"b\" & Sdeaths_norm > 0)\n",
    "# all = mortality_fit(cdata, response.col=\"Sdeaths_norm\")\n",
    "countrysub = subset(stratified, country==\"USA\" & age==\"65_74\" & sex==\"b\" & year >= 2012)\n",
    "plot_mortality(countrysub)\n",
    "plot_debug(countrysub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum age groups' deaths and population\n",
    "high_ages = subset(data, Age %in% c(\"65_74\", \"74_85\", \"85p\")) %>% group_by(Date, CountryCode, Sex) %>% \n",
    "    summarise(Sdeaths_norm=sum(Sdeaths_norm),\n",
    "             Date=Date, Week=Week, Year=Year, Age=\"all\") %>% distinct()\n",
    "mid_ages = subset(data, Age %in% c(\"15_64\")) %>% group_by(Date, CountryCode, Sex) %>% \n",
    "    summarise(Sdeaths_norm=sum(Sdeaths_norm),\n",
    "             Date=Date, Week=Week, Year=Year, Age=\"all\") %>% distinct()\n",
    "adult_ages = subset(data, Age %in% c(\"15_64\",\"65_74\", \"74_85\", \"85p\")) %>% group_by(Date, CountryCode, Sex) %>% \n",
    "    summarise(Sdeaths_norm=sum(Sdeaths_norm),\n",
    "             Date=Date, Week=Week, Year=Year, Age=\"all\") %>% distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0e0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit all countries\n",
    "res_high = high_ages %>% group_by(CountryCode, Sex) %>% group_map(~ mortality_fit(.x), keep=TRUE)\n",
    "high_ages_df = do.call(rbind, res_high)\n",
    "res_mid = mid_ages %>% group_by(CountryCode, Sex) %>% group_map(~ mortality_fit(.x), keep=TRUE)\n",
    "mid_ages_df = do.call(rbind, res_mid)\n",
    "res_adult = adult_ages %>% group_by(CountryCode, Sex) %>% group_map(~ mortality_fit(.x), keep=TRUE)\n",
    "adult_ages_df = do.call(rbind, res_adult)\n",
    "\n",
    "all_ages_df = rbind(high=high_ages_df, mid=mid_ages_df)\n",
    "all_ages_df = rbind(high=high_ages_df, mid=mid_ages_df, adult=adult_ages_df)\n",
    "all_ages_df$age_group = rownames(all_ages_df)\n",
    "all_ages_df$age_group = gsub(\"\\\\.*\\\\d\", \"\", all_ages_df$age_group)\n",
    "all_ages_df$age_group = gsub(\".Sex\", \"\", all_ages_df$age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f47f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=25, repr.plot.height=10)\n",
    "p = ggplot(subset(all_ages_df, age_group==\"high\" & sex==\"b\" & year >= 2019), aes(date, get_percentage(centered))) + geom_line(alpha=0.8) + \n",
    "# geom_smooth(method=\"lm\", formula=y ~ ns(x, df=16), se=FALSE) +\n",
    "geom_ribbon(aes(ymin=get_percentage(centered_low), ymax=get_percentage(centered_high)), alpha=0.3) + \n",
    "labs(x=\"Date\", y=\"Deaths [% from baseline 2014-2019]\", title=\"Anomalous Mortality 2012-2022\") + \n",
    "facet_wrap(~country, scales=\"free_y\")\n",
    "p\n",
    "ggsave(p,file=\"../figures/all_countries_smooth_high_age.pdf\", width=25, height=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=25, repr.plot.height=10)\n",
    "p = ggplot(subset(mid_ages_df, sex==\"b\" & year >= 2019), aes(date, get_percentage(centered))) + geom_line(alpha=0.8) + \n",
    "# geom_smooth(method=\"lm\", formula=y ~ ns(x, df=16), se=FALSE) +\n",
    "geom_ribbon(aes(ymin=get_percentage(centered_low), ymax=get_percentage(centered_high)), alpha=0.3) + \n",
    "labs(x=\"Date\", y=\"Deaths [% from baseline 2014-2019]\", title=\"Anomalous Mortality 2012-2022\") + \n",
    "facet_wrap(~country, scales=\"free_y\")\n",
    "p\n",
    "ggsave(p,file=\"../figures/all_countries_smooth_mid_age.pdf\", width=25, height=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6634b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate to find best smoothing parameter by minimizing out-of-sample \n",
    "# deviation from estimated exceedence. I.e. for a 95% confidence band, we will expect \n",
    "# 5% of out-of-sample estimates to be outside this band. We thus choose the smallest number \n",
    "# of parameters that get us there.\n",
    "# Conclusion: The predictive power is not dependent on degrees of freedom of smoothing\n",
    "# options(repr.plot.width=7, repr.plot.height=4)\n",
    "cv_mortality = function(cdata,\n",
    "                       years_per_df = 5,\n",
    "                       test_start_year = 2020,\n",
    "                       cv_type=\"week\",  # week or \"res\" for residuals spline degrees of freedom\n",
    "                       dfs=c(2, 4, 6, 8, 10, 12, 14, 16, 18, 20),\n",
    "                       df_other=2,\n",
    "                       response=\"Sdeaths_norm\") {\n",
    "\n",
    "    # TODO: make df_opther into a vector of same length as dfs\n",
    "    \n",
    "    all = cdata %>% rename(week=Week, year=Year, age=Age, date=Date, country=CountryCode, sex=Sex, \n",
    "                     response=all_of(response))\n",
    "    all$week = as.numeric(all$week)\n",
    "    all$year = as.numeric(all$year)\n",
    "    \n",
    "    df.yearly = floor(max((test_start_year - min(all$year)) / years_per_df, 2))\n",
    "    train = subset(all, year < 2020 & year > 2012)\n",
    "    alpha = 0.05 # Confidence interval\n",
    "\n",
    "    years = unique(train$year)\n",
    "    n_years = length(years)\n",
    "    n_dfs = length(dfs)\n",
    "    te_hat = matrix(0, n_years, n_dfs)\n",
    "    tr_hat = matrix(0, n_years, n_dfs)\n",
    "    sd_ratio_hat = matrix(0, n_years, n_dfs)\n",
    "    INFL = 1.\n",
    "    out = vector(mode=\"list\", length=n_years)\n",
    "    if (cv_type == \"week\") {\n",
    "        dfs_week = dfs\n",
    "        dfs_res = rep(df_other, length(dfs))\n",
    "    } else if (cv_type == \"res\") {\n",
    "        dfs_res = dfs\n",
    "        dfs_week = rep(df_other, length(dfs))\n",
    "    }\n",
    "\n",
    "    for (i in 1:n_years) {\n",
    "        out[[i]] = vector(mode=\"list\", length=n_dfs)\n",
    "\n",
    "        for (j in 1:n_dfs) {\n",
    "            m_year = years[i]\n",
    "            \n",
    "            tr = subset(train, year != m_year)\n",
    "            te = subset(train, year == m_year)\n",
    "            n_tr = nrow(tr)\n",
    "            n_te = nrow(te)\n",
    "            yearly.fit = rq(response ~ ns(date, df=df.yearly), data=tr)\n",
    "\n",
    "            tr[, \"res.yearly\"] = yearly.fit$res\n",
    "            tr[, \"fit.yearly\"] = yearly.fit$fit\n",
    "\n",
    "            if (dfs_week[j] <= 2) {\n",
    "                weekly.fit = rq(res.yearly ~ week, data=tr)\n",
    "            } else {\n",
    "                weekly.fit = rq(res.yearly ~ 0 + pbs(week, df=dfs_week[j]), data=tr)\n",
    "            }\n",
    "\n",
    "            tr[, \"fit.weekly\"] = weekly.fit$fit\n",
    "            tr[, \"res.weekly\"] = weekly.fit$res\n",
    "            tr = tr %>% mutate(centered = response - fit.weekly - fit.yearly)\n",
    "            te$fit.yearly = predict(yearly.fit, newdata=te)\n",
    "            te$fit.weekly = predict(weekly.fit, newdata=te)\n",
    "\n",
    "            te = te %>% mutate(centered = response - fit.weekly - fit.yearly)\n",
    "\n",
    "            if (dfs_res[j] <= 2) {\n",
    "                fit.low = quantile(tr$centered, alpha/2)\n",
    "                fit.high = quantile(tr$centered, 1 - alpha/2)      \n",
    "                tr$high = rep(fit.high, n_tr)\n",
    "                tr$low = rep(fit.low, n_tr)\n",
    "                te$high = rep(fit.high, n_te)\n",
    "                te$low = rep(fit.low, n_te)\n",
    "            } else {\n",
    "                fit.low = rq(centered ~ 0 + pbs(week, df=dfs_res[j]), data=tr, tau=alpha/2)\n",
    "                fit.high = rq(centered ~ 0 + pbs(week, df=dfs_res[j]), data=tr, tau=1-alpha/2)\n",
    "                tr$high = fit.high$fit\n",
    "                tr$low = fit.low$fit\n",
    "                te$high = predict(fit.high, newdata=te)\n",
    "                te$low = predict(fit.low, newdata=te)\n",
    "            }\n",
    "            \n",
    "            sd_ratio_hat[i, j] = sd(te$centered) / sd(tr$centered)\n",
    "            tr_hat[i, j] = 1 - (sum(tr$low > tr$centered | tr$high < tr$centered) / nrow(tr))\n",
    "            te_hat[i, j] = 1 - (sum(te$low > te$centered | te$high < te$centered) / nrow(te))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    te_oos_error = data.frame(mean=apply(te_hat, 2, median), upper=apply(te_hat, 2, quantile, .75), lower=apply(te_hat, 2, quantile, .25), dfs=dfs)\n",
    "    tr_oos_error = data.frame(mean=apply(tr_hat, 2, median), upper=apply(tr_hat, 2, quantile, .75), lower=apply(tr_hat, 2, quantile, .25), dfs=dfs)\n",
    "    oos_error = rbind(train=tr_oos_error, test=te_oos_error)\n",
    "    oos_error$data_set = rownames(oos_error)\n",
    "    oos_error$data_set = gsub(\"\\\\.*\\\\d\", \"\", oos_error$data_set)\n",
    "    oos_error$sex = all$sex[1]  # all rows in input must be same sex\n",
    "    oos_error$country = all$country[1]  # all rows in input must be same sex\n",
    "    return(oos_error)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca6c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_error = cv_mortality(high_ages %>% filter(CountryCode == \"USA\" & Sex == \"b\"))\n",
    "tail(oos_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0478038",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos_error = cv_mortality(high_ages %>% filter(CountryCode == \"USA\" & Sex == \"b\"), cv_type=\"res\", df_other=4)\n",
    "tail(oos_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0cceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_high_ages = subset(high_ages, Sex==\"b\") %>% group_by(CountryCode) %>% group_map(~ cv_mortality(.x), keep=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add00ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate residual envelopes/quantiles degrees of freedom while keeping the weekly estimates fixed\n",
    "cv_res_high_ages = subset(high_ages, Sex==\"b\") %>% group_by(CountryCode) %>% \n",
    "    group_map(~ cv_mortality(.x, cv_type=\"res\", df_other=4), keep=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7193c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=20, repr.plot.height=18)\n",
    "p = ggplot(do.call(rbind, cv_high_ages),\n",
    "      aes(x=dfs, mean, ymin=lower, ymax=upper, color=data_set)) + geom_errorbar() +\n",
    "    theme_bw() +\n",
    "    facet_wrap(~country) +\n",
    "    labs(y=\"Probability of exceedence\", x=\"Weekly spline degrees of freedom\", \n",
    "    title=\"Estimation of model coverage\")\n",
    "p\n",
    "ggsave(p, file=\"../figures/all_countries_cv.pdf\", width=20, height=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe20f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=20, repr.plot.height=18)\n",
    "p = ggplot(do.call(rbind, cv_res_high_ages),\n",
    "      aes(x=dfs, mean, ymin=lower, ymax=upper, color=data_set)) + geom_errorbar() +\n",
    "    theme_bw() +\n",
    "    facet_wrap(~country) +\n",
    "    labs(y=\"Probability of exceedence\", x=\"Weekly spline degrees of freedom\", \n",
    "    title=\"Estimation of model coverage\")\n",
    "p\n",
    "ggsave(p, file=\"../figures/all_countries_cv_res.pdf\", width=20, height=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0008efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=9, repr.plot.height=6)\n",
    "ggplot(do.call(rbind, cv_all_ages) %>% filter(country==\"USA\"), \n",
    "       aes(x=dfs, mean, ymin=lower, ymax=upper, color=data_set)) + geom_errorbar() +\n",
    "theme_bw() +\n",
    "theme(plot.title=element_text(hjust=.5), \n",
    "      legend.key.size=unit(0.7, \"cm\"),\n",
    "#      legend.position = c(0.18, 0.15),\n",
    "     legend.title=element_blank()) + \n",
    "labs(y=\"Probability of exceedence\", x=\"Weekly spline degrees of freedom\", \n",
    "     title=\"Estimation of model coverage\") +\n",
    "scale_color_discrete(\"\", labels=c(\"Test\", \"Train\"))\n",
    "# ggsave(get_figloc(\"cv_pois_s2008.pdf\"), width=7, height=4)\n",
    "# ggsave(get_figloc(\"cv_pois_s2008.png\"), width=7, height=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1422a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=30, repr.plot.height=21)\n",
    "p = ggplot(subset(high_ages_df, sex != \"b\" & year >= 2019), aes(date, get_percentage(centered)), color=sex) + geom_line(aes(color=sex)) + \n",
    "# geom_smooth(method=\"lm\", formula=y ~ ns(x, df=16), se=FALSE) +\n",
    "geom_ribbon(aes(ymin=get_percentage(centered_low), ymax=get_percentage(centered_high), color=sex), alpha=0, linetype=2) + \n",
    "labs(x=\"Date\", y=\"Deaths [% from baseline 2014-2019]\", title=\"Anomalous Mortality 2012-2022\") + \n",
    "facet_wrap(~country, scales=\"free_y\") + scale_color_discrete(\"\", labels=c(\"Female\", \"Male\"))\n",
    "p\n",
    "ggsave(p, file=\"../figures/all_countries_smooth_high_age_by_gender.pdf\", width=25, height=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=30, repr.plot.height=21)\n",
    "p = ggplot(subset(all_ages_df, sex == \"b\" & year >= 2019), aes(date, get_percentage(centered)), color=age_group) + geom_line(aes(color=age_group)) + \n",
    "# geom_smooth(method=\"lm\", formula=y ~ ns(x, df=16), se=FALSE) +\n",
    "geom_ribbon(aes(ymin=get_percentage(centered_low), ymax=get_percentage(centered_high), color=age_group), alpha=0, linetype=2) + \n",
    "labs(x=\"Date\", y=\"Deaths [% from baseline 2014-2019]\", title=\"Anomalous Mortality 2012-2022\") + \n",
    "facet_wrap(~country, scales=\"free_y\") + scale_color_discrete(\"\", labels=c(\"High (65+)\", \"Mid (15-64)\"))\n",
    "p\n",
    "ggsave(p, file=\"../figures/all_countries_smooth_both_gender_by_age_type.pdf\", width=25, height=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit single country and sex\n",
    "options(repr.plot.width=7, repr.plot.height=4)\n",
    "cdata = subset(high_ages, CountryCode==\"NOR\" & Sex==\"b\")\n",
    "all = mortality_fit(cdata)\n",
    "plot_mortality(all)\n",
    "plot_debug(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a199b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data for possible further analysis.\n",
    "head(all_ages_df)\n",
    "write.csv(all_ages_df, \"../data/mortality_all_ages_normalized.csv\")\n",
    "write.csv(stratified, \"../data/mortality_stratified_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c4cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
